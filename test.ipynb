{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from models.Resnet_model import get_resnet18  # Adjust this import based on your structure\n",
    "\n",
    "# Test dataset path and device configuration\n",
    "test_data_path = r\"C:\\Users\\Lenovo\\Desktop\\ai_project\\datasets\\currencyDataset\"  # Path to test dataset\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define test transformations (same as used during training/validation)\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load test dataset with transformations\n",
    "test_dataset = ImageFolder(root=test_data_path, transform=test_transforms)\n",
    "class_names = test_dataset.classes  # Retrieve class names\n",
    "\n",
    "# Create DataLoader for test dataset\n",
    "test_loader = DataLoader(test_dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "\n",
    "def load_model(model_path, num_classes, device):\n",
    "    \"\"\"\n",
    "    Load the model from a checkpoint.\n",
    "\n",
    "    Args:\n",
    "        model_path (str): Path to the saved checkpoint file.\n",
    "        num_classes (int): Number of classes for the model.\n",
    "        device (torch.device): Device to load the model on (CPU/GPU).\n",
    "\n",
    "    Returns:\n",
    "        torch.nn.Module: The loaded model.\n",
    "    \"\"\"\n",
    "    # Initialize the model\n",
    "    model = get_resnet18(num_classes=num_classes)\n",
    "    \n",
    "    # Load checkpoint\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    if \"state_dict\" in checkpoint:  # Handle case where checkpoint contains extra metadata\n",
    "        model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    else:\n",
    "        model.load_state_dict(checkpoint)  # Directly load if it's a plain state_dict\n",
    "    \n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "def test_model(model, test_loader, class_names, device, num_images_to_display=20):\n",
    "    \"\"\"\n",
    "    Test the model and visualize predictions.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): Trained model.\n",
    "        test_loader (DataLoader): DataLoader for test dataset.\n",
    "        class_names (list): List of class names.\n",
    "        device (torch.device): Device to run the model on.\n",
    "        num_images_to_display (int): Number of test images to display.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    images_shown = 0\n",
    "    images_per_row = 5  # Number of images per row for visualization\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            predictions = outputs.argmax(dim=1)\n",
    "\n",
    "            # Visualize images\n",
    "            if images_shown < num_images_to_display:\n",
    "                images_np = images.cpu().numpy()\n",
    "                labels_np = labels.cpu().numpy()\n",
    "                predictions_np = predictions.cpu().numpy()\n",
    "\n",
    "                num_images = min(len(images), num_images_to_display - images_shown)\n",
    "                rows = (num_images + images_per_row - 1) // images_per_row  # Calculate rows needed\n",
    "                fig, axes = plt.subplots(rows, images_per_row, figsize=(15, 3 * rows))\n",
    "\n",
    "                if rows == 1:\n",
    "                    axes = [axes]  # Ensure axes is iterable if there's only one row\n",
    "\n",
    "                for i in range(num_images):\n",
    "                    row, col = divmod(i, images_per_row)\n",
    "                    ax = axes[row][col] if rows > 1 else axes[col]\n",
    "                    image = np.transpose(images_np[i], (1, 2, 0))  # Convert (C, H, W) to (H, W, C)\n",
    "\n",
    "                    # Unnormalize the image (reverse normalization)\n",
    "                    mean = np.array([0.485, 0.456, 0.406])\n",
    "                    std = np.array([0.229, 0.224, 0.225])\n",
    "                    image = (image * std + mean).clip(0, 1)\n",
    "\n",
    "                    ax.imshow(image)\n",
    "                    ax.set_title(f\"Pred: {class_names[predictions_np[i]]}\\nAct: {class_names[labels_np[i]]}\")\n",
    "                    ax.axis('off')\n",
    "\n",
    "                # Turn off unused subplots\n",
    "                for j in range(num_images, rows * images_per_row):\n",
    "                    row, col = divmod(j, images_per_row)\n",
    "                    ax = axes[row][col] if rows > 1 else axes[col]\n",
    "                    ax.axis('off')\n",
    "\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "\n",
    "                images_shown += num_images\n",
    "                if images_shown >= num_images_to_display:\n",
    "                    break\n",
    "\n",
    "\n",
    "# Paths and Configurations\n",
    "model_path = \"./checkpoints/saved_model.pth\"  # Path to your saved checkpoint\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load model\n",
    "model = load_model(model_path, num_classes=len(class_names), device=device)\n",
    "\n",
    "# Test and visualize predictions\n",
    "test_model(model, test_loader, class_names, device, num_images_to_display=80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
